{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:44.158788Z",
     "start_time": "2021-05-05T09:12:44.143927Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns;sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import Graphs\n",
    "import networkx as nx\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import pickle as pkl\n",
    "import pywt\n",
    "from tsmoothie.smoother import ExponentialSmoother\n",
    "from river import preprocessing,compose, base\n",
    "from datetime import timedelta\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchsummaryX import summary\n",
    "from operator import add\n",
    "from copy import deepcopy\n",
    "from scipy import signal, fftpack\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:45.229338Z",
     "start_time": "2021-05-05T09:12:44.822749Z"
    }
   },
   "outputs": [],
   "source": [
    "parse_date=[\"time\"]\n",
    "buildingDB = pd.read_csv(\"./buildingDB.csv\",header=0,index_col=0,parse_dates=parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:45.959592Z",
     "start_time": "2021-05-05T09:12:45.898616Z"
    }
   },
   "outputs": [],
   "source": [
    "babbage = buildingDB.loc[buildingDB[\"room\"]==\"babbage\"]\n",
    "babyfoot = buildingDB.loc[buildingDB[\"room\"]==\"babyfoot\"]\n",
    "jacquard = buildingDB.loc[buildingDB[\"room\"]==\"jacquard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:47.442140Z",
     "start_time": "2021-05-05T09:12:47.098548Z"
    }
   },
   "outputs": [],
   "source": [
    "babbage_nodata = set(jacquard.index) - set(babbage.index)\n",
    "jacquard = jacquard.drop(babbage_nodata,axis=0)\n",
    "babyfoot = babyfoot.drop(babbage_nodata,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:48.364469Z",
     "start_time": "2021-05-05T09:12:48.345789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67104, 7), (67104, 7), (67104, 7))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babbage = babbage.sort_index()\n",
    "jacquard = jacquard.sort_index()\n",
    "babyfoot = babyfoot.sort_index()\n",
    "babbage.shape, jacquard.shape, babyfoot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:14:27.342307Z",
     "start_time": "2021-05-05T09:14:27.328629Z"
    }
   },
   "outputs": [],
   "source": [
    "def Missing_values(data):\n",
    "    '''\n",
    "    Find missing values of the dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    Print a dataframe with missing values and their percentage.\n",
    "\n",
    "    '''\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total,percent], axis=1, keys=['Total', 'Pourcentage'])\n",
    "    #Affiche que les variables avec des na\n",
    "    print (missing_data[(percent>0)],'\\n' )\n",
    "    \n",
    "class DataTransform:\n",
    "    \n",
    "    def __init__(self, dataset, drop,interpol=True):\n",
    "        self.datatmp = dataset.drop(drop, axis=1)\n",
    "        #self.datatmp[\"weekofyear\"] = pd.Int64Index(dataset.index.isocalendar().week)\n",
    "        #self.datatmp[\"dateofmonth\"] = pd.DatetimeIndex(dataset.index).date\n",
    "        #self.datatmp[\"month\"] = pd.DatetimeIndex(dataset.index).month\n",
    "        self.interpol = interpol\n",
    "        \n",
    "    def interpolate(self,column):\n",
    "        \"Column interpolation\"\n",
    "        if column in self.datatmp.columns:\n",
    "            self.datatmp[column].interpolate(method=\"linear\",limit_direction=\"both\",inplace=True)\n",
    "        else:\n",
    "            print(\"Column not in data\")\n",
    "            \n",
    "    def dataByWeek(self):\n",
    "        \"Create week of year feature\"\n",
    "        weeks = dict()\n",
    "        for week in self.datatmp.weekofyear.unique():\n",
    "            weeks[week] = self.datatmp.loc[self.datatmp[\"weekofyear\"]==week]\n",
    "        return weeks\n",
    "    \n",
    "    def dataByMonth(self):\n",
    "        \"Create month of year feature\"\n",
    "        months = dict()\n",
    "        for month in self.datatmp.month.unique():\n",
    "            months[month] = self.datatmp.loc[self.datatmp[\"month\"]==month]\n",
    "        return months\n",
    "        \n",
    "    \n",
    "    def transform(self, interpol_columns):\n",
    "        if self.interpol:\n",
    "            self.interpolate(interpol_columns)\n",
    "        return self.datatmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:14:28.077391Z",
     "start_time": "2021-05-05T09:14:28.046590Z"
    }
   },
   "outputs": [],
   "source": [
    "babbagenew = DataTransform(babbage, [\"presence\",\"room\"]).transform(\"light\")\n",
    "babyfootnew = DataTransform(babyfoot, [\"presence\",\"room\"]).transform(\"light\")\n",
    "jacquardnew = DataTransform(jacquard, [\"presence\",\"room\"]).transform(\"light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:12:37.098829Z",
     "start_time": "2021-05-05T09:12:36.634594Z"
    }
   },
   "outputs": [],
   "source": [
    "#babbagenew=babbagenew.dropna(axis=0)\n",
    "#babyfootnew = babyfootnew.dropna(axis=0)\n",
    "#jacquardnew=jacquardnew.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:14:31.216563Z",
     "start_time": "2021-05-05T09:14:31.173239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Total, Pourcentage]\n",
      "Index: [] \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Total, Pourcentage]\n",
      "Index: [] \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Total, Pourcentage]\n",
      "Index: [] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Missing_values(babbagenew), Missing_values(babyfootnew), Missing_values(jacquardnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:36:36.517888Z",
     "start_time": "2021-05-03T09:36:36.510958Z"
    }
   },
   "outputs": [],
   "source": [
    "def createChunk(n_freq,dataset,path_to_folder):\n",
    "    \n",
    "    if not os.path.exists(path_to_folder):\n",
    "        os.makedirs(path_to_folder)\n",
    "    \n",
    "    start_idx = dataset.index.min()\n",
    "    data_week = np.unique(pd.Int64Index(dataset.index.isocalendar().week))\n",
    "    nextweek_idx = timedelta(weeks=n_freq)\n",
    "    nb_data_in_week = dataset[(dataset.index >= start_idx)  & (dataset.index < start_idx+nextweek_idx)].shape[0]\n",
    "    num_chunk = np.ceil(dataset.shape[0]/(nb_data_in_week))\n",
    "    i = 0\n",
    "    tmp_idx = start_idx\n",
    "    while i < num_chunk:\n",
    "        file_name = path_to_folder + \"chunk_\" + str(i) + \".csv\"\n",
    "        #os.makedirs(file_name)\n",
    "        weekly = tmp_idx + timedelta(weeks=n_freq)\n",
    "        chunk_i = dataset[(dataset.index >= tmp_idx) & (dataset.index < weekly)]            \n",
    "        chunk_i.to_csv(file_name)\n",
    "        tmp_idx = weekly\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:36:40.064958Z",
     "start_time": "2021-05-03T09:36:39.600423Z"
    }
   },
   "outputs": [],
   "source": [
    "path_jacquard = \"./QarnotData30m/jacquard/\"\n",
    "path_babyfoot = \"./QarnotData30m/babyfoot/\"\n",
    "path_babbage = \"./QarnotData30m/babbage/\"\n",
    "createChunk(n_freq=4, dataset=babbagenew, path_to_folder=path_babbage)\n",
    "createChunk(n_freq=4, dataset=jacquardnew, path_to_folder=path_jacquard)\n",
    "createChunk(n_freq=4, dataset=babyfootnew, path_to_folder=path_babyfoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:37:04.289087Z",
     "start_time": "2021-05-03T09:37:04.124305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage:chunk_0.csv nb_data : 1344 min_date : 2020-01-05 00:00:00 max_date : 2020-02-01 23:30:00\n",
      "jacquard:chunk_0.csv nb_data : 1344 min_date : 2020-01-05 00:00:00 max_date : 2020-02-01 23:30:00\n",
      "babyfoot:chunk_0.csv nb_data : 1344 min_date : 2020-01-05 00:00:00 max_date : 2020-02-01 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_1.csv nb_data : 1296 min_date : 2020-02-02 00:00:00 max_date : 2020-02-28 23:30:00\n",
      "jacquard:chunk_1.csv nb_data : 1296 min_date : 2020-02-02 00:00:00 max_date : 2020-02-28 23:30:00\n",
      "babyfoot:chunk_1.csv nb_data : 1296 min_date : 2020-02-02 00:00:00 max_date : 2020-02-28 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_2.csv nb_data : 1344 min_date : 2020-03-01 00:00:00 max_date : 2020-03-28 23:30:00\n",
      "jacquard:chunk_2.csv nb_data : 1344 min_date : 2020-03-01 00:00:00 max_date : 2020-03-28 23:30:00\n",
      "babyfoot:chunk_2.csv nb_data : 1344 min_date : 2020-03-01 00:00:00 max_date : 2020-03-28 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_3.csv nb_data : 1344 min_date : 2020-03-29 00:00:00 max_date : 2020-04-25 23:30:00\n",
      "jacquard:chunk_3.csv nb_data : 1344 min_date : 2020-03-29 00:00:00 max_date : 2020-04-25 23:30:00\n",
      "babyfoot:chunk_3.csv nb_data : 1344 min_date : 2020-03-29 00:00:00 max_date : 2020-04-25 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_4.csv nb_data : 1344 min_date : 2020-04-26 00:00:00 max_date : 2020-05-23 23:30:00\n",
      "jacquard:chunk_4.csv nb_data : 1344 min_date : 2020-04-26 00:00:00 max_date : 2020-05-23 23:30:00\n",
      "babyfoot:chunk_4.csv nb_data : 1344 min_date : 2020-04-26 00:00:00 max_date : 2020-05-23 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_5.csv nb_data : 1344 min_date : 2020-05-24 00:00:00 max_date : 2020-06-20 23:30:00\n",
      "jacquard:chunk_5.csv nb_data : 1344 min_date : 2020-05-24 00:00:00 max_date : 2020-06-20 23:30:00\n",
      "babyfoot:chunk_5.csv nb_data : 1344 min_date : 2020-05-24 00:00:00 max_date : 2020-06-20 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_6.csv nb_data : 1056 min_date : 2020-06-21 00:00:00 max_date : 2020-07-18 23:30:00\n",
      "jacquard:chunk_6.csv nb_data : 1056 min_date : 2020-06-21 00:00:00 max_date : 2020-07-18 23:30:00\n",
      "babyfoot:chunk_6.csv nb_data : 1056 min_date : 2020-06-21 00:00:00 max_date : 2020-07-18 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_7.csv nb_data : 1344 min_date : 2020-07-19 00:00:00 max_date : 2020-08-15 23:30:00\n",
      "jacquard:chunk_7.csv nb_data : 1344 min_date : 2020-07-19 00:00:00 max_date : 2020-08-15 23:30:00\n",
      "babyfoot:chunk_7.csv nb_data : 1344 min_date : 2020-07-19 00:00:00 max_date : 2020-08-15 23:30:00\n",
      "--------------------------\n",
      "babbage:chunk_8.csv nb_data : 768 min_date : 2020-08-16 00:00:00 max_date : 2020-08-31 23:30:00\n",
      "jacquard:chunk_8.csv nb_data : 768 min_date : 2020-08-16 00:00:00 max_date : 2020-08-31 23:30:00\n",
      "babyfoot:chunk_8.csv nb_data : 768 min_date : 2020-08-16 00:00:00 max_date : 2020-08-31 23:30:00\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "list_babbage = sorted(os.listdir(path_babbage))\n",
    "list_jacquard = sorted(os.listdir(path_jacquard))\n",
    "list_babyfoot = sorted(os.listdir(path_babyfoot))\n",
    "for babbage,jacquard,babyfoot in zip(list_babbage, list_jacquard,list_babyfoot):\n",
    "    chunk_babbage = pd.read_csv(path_babbage+babbage,index_col=0,parse_dates=[\"time\"])\n",
    "    print(\"babbage:{} nb_data : {} min_date : {} max_date : {}\".format(babbage, chunk_babbage.shape[0], chunk_babbage.index.min(), \n",
    "                                                                       chunk_babbage.index.max()))\n",
    "    \n",
    "    chunk_jacquard = pd.read_csv(path_jacquard+jacquard,index_col=0,parse_dates=[\"time\"])\n",
    "    print(\"jacquard:{} nb_data : {} min_date : {} max_date : {}\".format(jacquard, chunk_jacquard.shape[0], \n",
    "                                                                        chunk_jacquard.index.min(), chunk_jacquard.index.max()))\n",
    "    \n",
    "    chunk_babyfoot = pd.read_csv(path_babyfoot+babyfoot,index_col=0,parse_dates=[\"time\"])\n",
    "    print(\"babyfoot:{} nb_data : {} min_date : {} max_date : {}\".format(babyfoot, chunk_babyfoot.shape[0], \n",
    "                                                                        chunk_babyfoot.index.min(), chunk_babyfoot.index.max()))\n",
    "    \n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
